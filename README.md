# Cosine Similarity Analyzer ğŸ“ŠğŸ”

This Python script calculates the cosine similarity between an input paragraph and a set of stored paragraphs. It utilizes the TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer and cosine similarity metric to identify the most similar paragraph from the stored collection.

##Working of TF-IDF

1. **Term Frequency (TF)** ğŸ“Š: This is the frequency of a word in a document. It's calculated by dividing the number of times a word appears in a document by the total number of words in the document. Mathematically, it can be represented as:
    $$ TF(t) = \frac{\text{Number of times term t appears in a document}}{\text{Total number of terms in the document}} $$

2. **Inverse Document Frequency (IDF)** ğŸ”„: This measures the importance of a word in the entire corpus (a collection of documents). The words that occur less in all the documents and more in individual document contribute more towards differentiation. Mathematically, it can be represented as:
    $$ IDF(t) = \log_e\left(\frac{\text{Total number of documents}}{\text{Number of documents with term t in it}}\right) $$

3. **TF-IDF** ğŸ¯: It's the product of TF and IDF. A high TF-IDF score is often obtained by a high term frequency (in the given document) and a low document frequency of the term in the whole collection of documents. It signifies the importance of a word in a document in a corpus. Mathematically, it can be represented as:
    $$ TFIDF(t) = TF(t) \times IDF(t) $$

4. **Normalization** ğŸ§®: After calculating TF-IDF, the output matrix could be normalized using techniques like L2 normalization to smooth the data and avoid bias due to length of documents.

5. **Vectorization** ğŸ§©: Each document is then represented as a vector in n-dimensional space, where n is the number of unique terms across all documents. This vector can be used for further analysis like clustering, classification, similarity check etc.

Remember, the main idea behind TF-IDF is to penalize common words (like 'is', 'the', 'and') and reward rare words (which are more significant in understanding the context of the document) ğŸ“š.

## Usage Instructions ğŸ› ï¸

1. **Install Dependencies:**
   - Ensure you have the necessary dependencies installed. You can install them via pip:
     ```bash
     pip install pandas scikit-learn
     ```

2. **Set File Path:**
   - Update the `file_path` variable with the actual path to your Excel file containing the stored paragraphs.

3. **Run the Script:**
   - Execute the Python script.

4. **Define Input Paragraph:**
   - Modify the `input_paragraph` variable with the paragraph you wish to compare against the stored paragraphs.

5. **View Results:**
   - The script will display the most similar paragraph from the stored collection along with its similarity score.
   - Additionally, it will output the similarity scores of all paragraphs in the stored collection.



## Note ğŸ“Œ

This script is designed for educational and research purposes ğŸš€ğŸ”¬. Results may vary depending on the quality and quantity of stored paragraphs and the input provided. Always validate the accuracy of the results before making any decisions based on them.

